{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c347051c",
   "metadata": {},
   "source": [
    "# Vectorisation of tokens and similarity of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07eceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "\n",
    "import gensim\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66c7d3",
   "metadata": {},
   "source": [
    "## Create a list of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ae3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1='''Chat GPT is a highly popular AI-based program that people use for generating dialogues. The chatbot has a language-based model that the developer fine-tunes for human interaction in a conversational manner. \n",
    "It’s a simulated chatbot primarily designed for customer service; people use it for various other purposes. But what is it? If you are new to this Chat GPT, this guide is for you, so continue reading. \n",
    "What’s Chat GPT?\n",
    "Chat GPT is an AI chatbot auto-generative system created by Open AI for online customer care. It is a pre-trained generative chat, which makes use of (NLP) Natural Language Processing. The source of its data is textbooks, websites, and various articles, which it uses to model its own language for responding to human interaction.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eaa13ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chat GPT is a highly popular AI-based program that people use for generating dialogues. The chatbot has a language-based model that the developer fine-tunes for human interaction in a conversational manner. \\nIt’s a simulated chatbot primarily designed for customer service; people use it for various other purposes. But what is it? If you are new to this Chat GPT, this guide is for you, so continue reading. \\nWhat’s Chat GPT?\\nChat GPT is an AI chatbot auto-generative system created by Open AI for online customer care. It is a pre-trained generative chat, which makes use of (NLP) Natural Language Processing. The source of its data is textbooks, websites, and various articles, which it uses to model its own language for responding to human interaction.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91ceb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_2='''What is Chat GPT and why is everyone talking about it? On Twitter, blogs, and at the office, Chat GPT has taken over the conversation in marketing. However, not everyone is a fan.\n",
    "So what is Chat GPT? Who better to ask than Chat GPT itself? \n",
    "ChatGPT is a variant of the GPT (Generative Pre-training Transformer) language model specifically designed for generating text in a chatbot-like manner. It is trained on a large dataset of human-human conversations and can generate natural language responses to input prompts.\n",
    "In other words, it is a smart AI technology that will spit out factual, informative and well-written responses to given prompts. The technology presents endless potential with many applications to marketing including customer service, eCommerce, entertainment, resourcing and more! Along with these benefits, many professionals are questioning what such a helpful tool means for working freelancers and industry professionals.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6717c35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is Chat GPT and why is everyone talking about it? On Twitter, blogs, and at the office, Chat GPT has taken over the conversation in marketing. However, not everyone is a fan.\\nSo what is Chat GPT? Who better to ask than Chat GPT itself? \\nChatGPT is a variant of the GPT (Generative Pre-training Transformer) language model specifically designed for generating text in a chatbot-like manner. It is trained on a large dataset of human-human conversations and can generate natural language responses to input prompts.\\nIn other words, it is a smart AI technology that will spit out factual, informative and well-written responses to given prompts. The technology presents endless potential with many applications to marketing including customer service, eCommerce, entertainment, resourcing and more! Along with these benefits, many professionals are questioning what such a helpful tool means for working freelancers and industry professionals.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66f5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_3='''ChatGPT is a large language learning model that was designed to imitate human conversation. It can remember things you have said to it in the past and is capable of correcting itself when wrong.\n",
    "It writes in a human-like way and has a wealth of knowledge because it was trained on all sorts of text from the internet, such as Wikipedia, blog posts, books, and academic articles.\n",
    "It's easy to learn how to use ChatGPT, but what is more challenging is finding out what its biggest problems are. Here are some that are worth knowing about.\n",
    "1. ChatGPT Isn't Always Right\n",
    "It fails at basic math, can't seem to answer simple logic questions, and will even go as far as to argue completely incorrect facts. As social media users can attest, ChatGPT can get it wrong on more than one occasion.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953f4b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChatGPT is a large language learning model that was designed to imitate human conversation. It can remember things you have said to it in the past and is capable of correcting itself when wrong.\\nIt writes in a human-like way and has a wealth of knowledge because it was trained on all sorts of text from the internet, such as Wikipedia, blog posts, books, and academic articles.\\nIt's easy to learn how to use ChatGPT, but what is more challenging is finding out what its biggest problems are. Here are some that are worth knowing about.\\n1. ChatGPT Isn't Always Right\\nIt fails at basic math, can't seem to answer simple logic questions, and will even go as far as to argue completely incorrect facts. As social media users can attest, ChatGPT can get it wrong on more than one occasion.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cb66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_4='''Texting, chatting and online messaging can be used for much more than simply communicating with your friends. Online communication can help young people build and develop social skills and gives them a platform to share their skills and help each other out.\n",
    "Messaging and texting are among the most popular methods of communication among children and teenagers. A study by Common Sense Media in 2018 found that 70% of teenagers report using social media multiple times a day.\n",
    "Messaging and texting can be much more than ways to communicate. They can also be tools that help young people learn and master important skills.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c130f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Texting, chatting and online messaging can be used for much more than simply communicating with your friends. Online communication can help young people build and develop social skills and gives them a platform to share their skills and help each other out.\\nMessaging and texting are among the most popular methods of communication among children and teenagers. A study by Common Sense Media in 2018 found that 70% of teenagers report using social media multiple times a day.\\nMessaging and texting can be much more than ways to communicate. They can also be tools that help young people learn and master important skills.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747dbad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list\n",
    "\n",
    "docs=[doc_1,doc_2,doc_3,doc_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad169305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chat GPT is a highly popular AI-based program that people use for generating dialogues. The chatbot has a language-based model that the developer fine-tunes for human interaction in a conversational manner. \\nIt’s a simulated chatbot primarily designed for customer service; people use it for various other purposes. But what is it? If you are new to this Chat GPT, this guide is for you, so continue reading. \\nWhat’s Chat GPT?\\nChat GPT is an AI chatbot auto-generative system created by Open AI for online customer care. It is a pre-trained generative chat, which makes use of (NLP) Natural Language Processing. The source of its data is textbooks, websites, and various articles, which it uses to model its own language for responding to human interaction.', 'What is Chat GPT and why is everyone talking about it? On Twitter, blogs, and at the office, Chat GPT has taken over the conversation in marketing. However, not everyone is a fan.\\nSo what is Chat GPT? Who better to ask than Chat GPT itself? \\nChatGPT is a variant of the GPT (Generative Pre-training Transformer) language model specifically designed for generating text in a chatbot-like manner. It is trained on a large dataset of human-human conversations and can generate natural language responses to input prompts.\\nIn other words, it is a smart AI technology that will spit out factual, informative and well-written responses to given prompts. The technology presents endless potential with many applications to marketing including customer service, eCommerce, entertainment, resourcing and more! Along with these benefits, many professionals are questioning what such a helpful tool means for working freelancers and industry professionals.', \"ChatGPT is a large language learning model that was designed to imitate human conversation. It can remember things you have said to it in the past and is capable of correcting itself when wrong.\\nIt writes in a human-like way and has a wealth of knowledge because it was trained on all sorts of text from the internet, such as Wikipedia, blog posts, books, and academic articles.\\nIt's easy to learn how to use ChatGPT, but what is more challenging is finding out what its biggest problems are. Here are some that are worth knowing about.\\n1. ChatGPT Isn't Always Right\\nIt fails at basic math, can't seem to answer simple logic questions, and will even go as far as to argue completely incorrect facts. As social media users can attest, ChatGPT can get it wrong on more than one occasion.\", 'Texting, chatting and online messaging can be used for much more than simply communicating with your friends. Online communication can help young people build and develop social skills and gives them a platform to share their skills and help each other out.\\nMessaging and texting are among the most popular methods of communication among children and teenagers. A study by Common Sense Media in 2018 found that 70% of teenagers report using social media multiple times a day.\\nMessaging and texting can be much more than ways to communicate. They can also be tools that help young people learn and master important skills.']\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb04a7",
   "metadata": {},
   "source": [
    "## Choosing the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e181636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[]# List of all tokens\n",
    "for document in docs:\n",
    "    doc=nlp(document)\n",
    "    text=[] # List of tokens in the document\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and not token.like_num:\n",
    "            text.append(token.lemma_)\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d9fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Chat', 'GPT', 'highly', 'popular', 'AI', 'base', 'program', 'people', 'use', 'generating', 'dialogue', 'chatbot', 'language', 'base', 'model', 'developer', 'fine', 'tune', 'human', 'interaction', 'conversational', 'manner', '\\n', 'simulated', 'chatbot', 'primarily', 'design', 'customer', 'service', 'people', 'use', 'purpose', 'new', 'Chat', 'GPT', 'guide', 'continue', 'read', '\\n', 'Chat', 'GPT', '\\n', 'Chat', 'GPT', 'AI', 'chatbot', 'auto', 'generative', 'system', 'create', 'Open', 'AI', 'online', 'customer', 'care', 'pre', 'train', 'generative', 'chat', 'make', 'use', 'NLP', 'Natural', 'Language', 'Processing', 'source', 'data', 'textbook', 'website', 'article', 'use', 'model', 'language', 'respond', 'human', 'interaction'], ['Chat', 'GPT', 'talk', 'Twitter', 'blog', 'office', 'Chat', 'GPT', 'take', 'conversation', 'marketing', 'fan', '\\n', 'Chat', 'GPT', 'well', 'ask', 'Chat', 'GPT', '\\n', 'ChatGPT', 'variant', 'GPT', 'Generative', 'pre', 'training', 'Transformer', 'language', 'model', 'specifically', 'design', 'generate', 'text', 'chatbot', 'like', 'manner', 'train', 'large', 'dataset', 'human', 'human', 'conversation', 'generate', 'natural', 'language', 'response', 'input', 'prompt', '\\n', 'word', 'smart', 'AI', 'technology', 'spit', 'factual', 'informative', 'write', 'response', 'give', 'prompt', 'technology', 'present', 'endless', 'potential', 'application', 'marketing', 'include', 'customer', 'service', 'eCommerce', 'entertainment', 'resource', 'benefit', 'professional', 'question', 'helpful', 'tool', 'mean', 'work', 'freelancer', 'industry', 'professional'], ['ChatGPT', 'large', 'language', 'learning', 'model', 'design', 'imitate', 'human', 'conversation', 'remember', 'thing', 'say', 'past', 'capable', 'correct', 'wrong', '\\n', 'write', 'human', 'like', 'way', 'wealth', 'knowledge', 'train', 'sort', 'text', 'internet', 'Wikipedia', 'blog', 'post', 'book', 'academic', 'article', '\\n', 'easy', 'learn', 'use', 'chatgpt', 'challenging', 'find', 'big', 'problem', 'worth', 'know', '\\n', 'chatgpt', 'right', '\\n', 'fail', 'basic', 'math', 'answer', 'simple', 'logic', 'question', 'far', 'argue', 'completely', 'incorrect', 'fact', 'social', 'medium', 'user', 'attest', 'ChatGPT', 'wrong', 'occasion'], ['texting', 'chat', 'online', 'messaging', 'simply', 'communicate', 'friend', 'online', 'communication', 'help', 'young', 'people', 'build', 'develop', 'social', 'skill', 'give', 'platform', 'share', 'skill', 'help', '\\n', 'messaging', 'texting', 'popular', 'method', 'communication', 'child', 'teenager', 'study', 'Common', 'Sense', 'medium', 'find', 'teenager', 'report', 'social', 'medium', 'multiple', 'time', 'day', '\\n', 'messaging', 'texting', 'way', 'communicate', 'tool', 'help', 'young', 'people', 'learn', 'master', 'important', 'skill']]\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68c1e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddce042c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14df236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(len(texts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf68d71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "print(len(texts[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54194e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(texts[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94972b1",
   "metadata": {},
   "source": [
    "## Creation of a corpus\n",
    "\n",
    "Corpus is a collection of tokens in a dictionary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fd36851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(172 unique tokens: ['\\n', 'AI', 'Chat', 'GPT', 'Language']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dict_1=Dictionary(texts)\n",
    "print(dict_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba843d4e",
   "metadata": {},
   "source": [
    "## Giving an ID to each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "283f45cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'AI': 1, 'Chat': 2, 'GPT': 3, 'Language': 4, 'NLP': 5, 'Natural': 6, 'Open': 7, 'Processing': 8, 'article': 9, 'auto': 10, 'base': 11, 'care': 12, 'chat': 13, 'chatbot': 14, 'continue': 15, 'conversational': 16, 'create': 17, 'customer': 18, 'data': 19, 'design': 20, 'developer': 21, 'dialogue': 22, 'fine': 23, 'generating': 24, 'generative': 25, 'guide': 26, 'highly': 27, 'human': 28, 'interaction': 29, 'language': 30, 'make': 31, 'manner': 32, 'model': 33, 'new': 34, 'online': 35, 'people': 36, 'popular': 37, 'pre': 38, 'primarily': 39, 'program': 40, 'purpose': 41, 'read': 42, 'respond': 43, 'service': 44, 'simulated': 45, 'source': 46, 'system': 47, 'textbook': 48, 'train': 49, 'tune': 50, 'use': 51, 'website': 52, 'ChatGPT': 53, 'Generative': 54, 'Transformer': 55, 'Twitter': 56, 'application': 57, 'ask': 58, 'benefit': 59, 'blog': 60, 'conversation': 61, 'dataset': 62, 'eCommerce': 63, 'endless': 64, 'entertainment': 65, 'factual': 66, 'fan': 67, 'freelancer': 68, 'generate': 69, 'give': 70, 'helpful': 71, 'include': 72, 'industry': 73, 'informative': 74, 'input': 75, 'large': 76, 'like': 77, 'marketing': 78, 'mean': 79, 'natural': 80, 'office': 81, 'potential': 82, 'present': 83, 'professional': 84, 'prompt': 85, 'question': 86, 'resource': 87, 'response': 88, 'smart': 89, 'specifically': 90, 'spit': 91, 'take': 92, 'talk': 93, 'technology': 94, 'text': 95, 'tool': 96, 'training': 97, 'variant': 98, 'well': 99, 'word': 100, 'work': 101, 'write': 102, 'Wikipedia': 103, 'academic': 104, 'answer': 105, 'argue': 106, 'attest': 107, 'basic': 108, 'big': 109, 'book': 110, 'capable': 111, 'challenging': 112, 'chatgpt': 113, 'completely': 114, 'correct': 115, 'easy': 116, 'fact': 117, 'fail': 118, 'far': 119, 'find': 120, 'imitate': 121, 'incorrect': 122, 'internet': 123, 'know': 124, 'knowledge': 125, 'learn': 126, 'learning': 127, 'logic': 128, 'math': 129, 'medium': 130, 'occasion': 131, 'past': 132, 'post': 133, 'problem': 134, 'remember': 135, 'right': 136, 'say': 137, 'simple': 138, 'social': 139, 'sort': 140, 'thing': 141, 'user': 142, 'way': 143, 'wealth': 144, 'worth': 145, 'wrong': 146, 'Common': 147, 'Sense': 148, 'build': 149, 'child': 150, 'communicate': 151, 'communication': 152, 'day': 153, 'develop': 154, 'friend': 155, 'help': 156, 'important': 157, 'master': 158, 'messaging': 159, 'method': 160, 'multiple': 161, 'platform': 162, 'report': 163, 'share': 164, 'simply': 165, 'skill': 166, 'study': 167, 'teenager': 168, 'texting': 169, 'time': 170, 'young': 171}\n"
     ]
    }
   ],
   "source": [
    "print(dict_1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b91836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fd358",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab7a99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vec=[]\n",
    "for token in texts:\n",
    "    bow_vec.append(dict_1.doc2bow(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c0e3826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 3), (1, 3), (2, 4), (3, 4), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 3), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 2), (29, 2), (30, 2), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 4), (52, 1)], [(0, 3), (1, 1), (2, 4), (3, 5), (14, 1), (18, 1), (20, 1), (28, 2), (30, 2), (32, 1), (33, 1), (38, 1), (44, 1), (49, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 2), (86, 1), (87, 1), (88, 2), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 2), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1)], [(0, 4), (9, 1), (20, 1), (28, 2), (30, 1), (33, 1), (49, 1), (51, 1), (53, 2), (60, 1), (61, 1), (76, 1), (77, 1), (86, 1), (95, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 2), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 2)], [(0, 2), (13, 1), (35, 2), (36, 2), (37, 1), (70, 1), (96, 1), (120, 1), (126, 1), (130, 2), (139, 2), (143, 1), (147, 1), (148, 1), (149, 1), (150, 1), (151, 2), (152, 2), (153, 1), (154, 1), (155, 1), (156, 3), (157, 1), (158, 1), (159, 3), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 3), (167, 1), (168, 2), (169, 3), (170, 1), (171, 2)]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77dffa8",
   "metadata": {},
   "source": [
    "## Creating BOW Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07eefb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import corpus2dense\n",
    "\n",
    "bow_matrix=corpus2dense(bow_vec,num_terms=len(dict_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ee8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3. 4. 2.]\n",
      " [3. 1. 0. 0.]\n",
      " [4. 4. 0. 0.]\n",
      " [4. 5. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 1.]\n",
      " [3. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [2. 2. 2. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [2. 2. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [2. 1. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 2.]\n",
      " [2. 0. 0. 2.]\n",
      " [1. 0. 0. 1.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [4. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 2. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 2. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 2.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 2. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 0. 0. 3.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cae1500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3915152",
   "metadata": {},
   "source": [
    "## TFIDF Vectorisation\n",
    "\n",
    "Term Frequency Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d102bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "tfidf=TfidfModel(bow_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ab18b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=4, num_nnz=214)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bea102cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec=[]\n",
    "for vec in bow_vec:\n",
    "    tfidf_vec.append(tfidf[vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59f4ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 0.18920325824137527), (2, 0.25227101098850035), (3, 0.25227101098850035), (4, 0.12613550549425018), (5, 0.12613550549425018), (6, 0.12613550549425018), (7, 0.12613550549425018), (8, 0.12613550549425018), (9, 0.06306775274712509), (10, 0.12613550549425018), (11, 0.25227101098850035), (12, 0.12613550549425018), (13, 0.06306775274712509), (14, 0.18920325824137527), (15, 0.12613550549425018), (16, 0.12613550549425018), (17, 0.12613550549425018), (18, 0.12613550549425018), (19, 0.12613550549425018), (20, 0.026175482385303223), (21, 0.12613550549425018), (22, 0.12613550549425018), (23, 0.12613550549425018), (24, 0.12613550549425018), (25, 0.25227101098850035), (26, 0.12613550549425018), (27, 0.12613550549425018), (28, 0.05235096477060645), (29, 0.25227101098850035), (30, 0.05235096477060645), (31, 0.12613550549425018), (32, 0.06306775274712509), (33, 0.05235096477060645), (34, 0.12613550549425018), (35, 0.06306775274712509), (36, 0.12613550549425018), (37, 0.06306775274712509), (38, 0.06306775274712509), (39, 0.12613550549425018), (40, 0.12613550549425018), (41, 0.12613550549425018), (42, 0.12613550549425018), (43, 0.12613550549425018), (44, 0.06306775274712509), (45, 0.12613550549425018), (46, 0.12613550549425018), (47, 0.12613550549425018), (48, 0.12613550549425018), (49, 0.026175482385303223), (50, 0.12613550549425018), (51, 0.25227101098850035), (52, 0.12613550549425018)], [(1, 0.05833161976223527), (2, 0.23332647904894108), (3, 0.2916580988111764), (14, 0.05833161976223527), (18, 0.05833161976223527), (20, 0.024209809595002508), (28, 0.048419619190005016), (30, 0.048419619190005016), (32, 0.05833161976223527), (33, 0.024209809595002508), (38, 0.05833161976223527), (44, 0.05833161976223527), (49, 0.024209809595002508), (53, 0.05833161976223527), (54, 0.11666323952447054), (55, 0.11666323952447054), (56, 0.11666323952447054), (57, 0.11666323952447054), (58, 0.11666323952447054), (59, 0.11666323952447054), (60, 0.05833161976223527), (61, 0.11666323952447054), (62, 0.11666323952447054), (63, 0.11666323952447054), (64, 0.11666323952447054), (65, 0.11666323952447054), (66, 0.11666323952447054), (67, 0.11666323952447054), (68, 0.11666323952447054), (69, 0.23332647904894108), (70, 0.05833161976223527), (71, 0.11666323952447054), (72, 0.11666323952447054), (73, 0.11666323952447054), (74, 0.11666323952447054), (75, 0.11666323952447054), (76, 0.05833161976223527), (77, 0.05833161976223527), (78, 0.23332647904894108), (79, 0.11666323952447054), (80, 0.11666323952447054), (81, 0.11666323952447054), (82, 0.11666323952447054), (83, 0.11666323952447054), (84, 0.23332647904894108), (85, 0.23332647904894108), (86, 0.05833161976223527), (87, 0.11666323952447054), (88, 0.23332647904894108), (89, 0.11666323952447054), (90, 0.11666323952447054), (91, 0.11666323952447054), (92, 0.11666323952447054), (93, 0.11666323952447054), (94, 0.23332647904894108), (95, 0.05833161976223527), (96, 0.05833161976223527), (97, 0.11666323952447054), (98, 0.11666323952447054), (99, 0.11666323952447054), (100, 0.11666323952447054), (101, 0.11666323952447054), (102, 0.05833161976223527)], [(9, 0.07082088165613964), (20, 0.029393321619287132), (28, 0.058786643238574264), (30, 0.029393321619287132), (33, 0.029393321619287132), (49, 0.029393321619287132), (51, 0.07082088165613964), (53, 0.1416417633122793), (60, 0.07082088165613964), (61, 0.07082088165613964), (76, 0.07082088165613964), (77, 0.07082088165613964), (86, 0.07082088165613964), (95, 0.07082088165613964), (102, 0.07082088165613964), (103, 0.1416417633122793), (104, 0.1416417633122793), (105, 0.1416417633122793), (106, 0.1416417633122793), (107, 0.1416417633122793), (108, 0.1416417633122793), (109, 0.1416417633122793), (110, 0.1416417633122793), (111, 0.1416417633122793), (112, 0.1416417633122793), (113, 0.2832835266245586), (114, 0.1416417633122793), (115, 0.1416417633122793), (116, 0.1416417633122793), (117, 0.1416417633122793), (118, 0.1416417633122793), (119, 0.1416417633122793), (120, 0.07082088165613964), (121, 0.1416417633122793), (122, 0.1416417633122793), (123, 0.1416417633122793), (124, 0.1416417633122793), (125, 0.1416417633122793), (126, 0.07082088165613964), (127, 0.1416417633122793), (128, 0.1416417633122793), (129, 0.1416417633122793), (130, 0.07082088165613964), (131, 0.1416417633122793), (132, 0.1416417633122793), (133, 0.1416417633122793), (134, 0.1416417633122793), (135, 0.1416417633122793), (136, 0.1416417633122793), (137, 0.1416417633122793), (138, 0.1416417633122793), (139, 0.07082088165613964), (140, 0.1416417633122793), (141, 0.1416417633122793), (142, 0.1416417633122793), (143, 0.07082088165613964), (144, 0.1416417633122793), (145, 0.1416417633122793), (146, 0.2832835266245586)], [(13, 0.05783149319662402), (35, 0.11566298639324804), (36, 0.11566298639324804), (37, 0.05783149319662402), (70, 0.05783149319662402), (96, 0.05783149319662402), (120, 0.05783149319662402), (126, 0.05783149319662402), (130, 0.11566298639324804), (139, 0.11566298639324804), (143, 0.05783149319662402), (147, 0.11566298639324804), (148, 0.11566298639324804), (149, 0.11566298639324804), (150, 0.11566298639324804), (151, 0.23132597278649608), (152, 0.23132597278649608), (153, 0.11566298639324804), (154, 0.11566298639324804), (155, 0.11566298639324804), (156, 0.34698895917974415), (157, 0.11566298639324804), (158, 0.11566298639324804), (159, 0.34698895917974415), (160, 0.11566298639324804), (161, 0.11566298639324804), (162, 0.11566298639324804), (163, 0.11566298639324804), (164, 0.11566298639324804), (165, 0.11566298639324804), (166, 0.34698895917974415), (167, 0.11566298639324804), (168, 0.23132597278649608), (169, 0.34698895917974415), (170, 0.11566298639324804), (171, 0.23132597278649608)]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22c20631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(tfidf_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74544c",
   "metadata": {},
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a265da",
   "metadata": {},
   "source": [
    "## Similarity of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc90f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import MatrixSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3b13afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=MatrixSimilarity(tfidf_vec,num_features=len(dict_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f06ceba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixSimilarity<4 docs, 172 features>\n"
     ]
    }
   ],
   "source": [
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0155a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999999  0.18051012 0.03002641 0.02917842]\n"
     ]
    }
   ],
   "source": [
    "print(sim[tfidf_vec[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76b935cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02917842 0.00674681 0.02866974 0.9999999 ]\n"
     ]
    }
   ],
   "source": [
    "print(sim[tfidf_vec[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
